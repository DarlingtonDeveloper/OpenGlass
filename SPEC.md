# OpenGlass ğŸ•¶ï¸ â€” Project Specification

**Version:** 0.1 (Draft)
**Author:** Mike
**Date:** 11 February 2026
**Status:** Planning

---

## Vision

OpenGlass is a real-time AI-powered smart glasses interface that connects Meta Ray-Ban glasses to Gemini Live and OpenClaw, turning them into a personal AI companion with eyes, ears, and hands. Built as a Swift iOS app, it goes beyond basic voice+vision by layering on use cases like real-time Mandarin translation, QR code â†’ action pipelines, contextual scene understanding, and agentic task execution.

Inspired by [VisionClaw](https://github.com/sseanliu/VisionClaw) by Sean Liu. OpenGlass takes the same proven Gemini Live + OpenClaw foundation and extends it with a richer use-case layer and cleaner architecture.

## Architecture Overview

```
Meta Ray-Ban Glasses (or iPhone camera fallback)
       â”‚
       â”‚  video frames (DAT SDK, 24fps) + mic audio
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OpenGlass iOS App (Swift)           â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Vision   â”‚  â”‚  Audio   â”‚  â”‚  Mode Router  â”‚  â”‚
â”‚  â”‚ Pipeline â”‚  â”‚ Pipeline â”‚  â”‚               â”‚  â”‚
â”‚  â”‚          â”‚  â”‚          â”‚  â”‚ â€¢ Assistant   â”‚  â”‚
â”‚  â”‚ â€¢ Frames â”‚  â”‚ â€¢ Mic In â”‚  â”‚ â€¢ Translator  â”‚  â”‚
â”‚  â”‚   @1fps  â”‚  â”‚   16kHz  â”‚  â”‚ â€¢ QR Scanner  â”‚  â”‚
â”‚  â”‚ â€¢ JPEG   â”‚  â”‚   PCM    â”‚  â”‚ â€¢ Spotter     â”‚  â”‚
â”‚  â”‚   encode â”‚  â”‚   chunks â”‚  â”‚ â€¢ Custom...   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚             â”‚                â”‚           â”‚
â”‚       â–¼             â–¼                â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         Gemini Live WebSocket            â”‚    â”‚
â”‚  â”‚     (vision + audio + tool calling)      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                     â”‚                            â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚       â–¼             â–¼             â–¼              â”‚
â”‚  Audio Out     Tool Calls    Transcript          â”‚
â”‚  (speaker)         â”‚         (on-screen)         â”‚
â”‚                    â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         OpenClaw Gateway (LAN)           â”‚    â”‚
â”‚  â”‚    http://<mac>.local:18789              â”‚    â”‚
â”‚  â”‚    56+ skills: web, messaging, smart     â”‚    â”‚
â”‚  â”‚    home, lists, reminders, etc.          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Components

### 1. Vision Pipeline
- Captures video frames from Meta Ray-Ban glasses via the DAT (Direct Audio Transfer) SDK, or falls back to the iPhone's rear camera
- Throttles to ~1 fps for Gemini consumption (configurable)
- JPEG-encodes each frame at 80% quality, ~100KB target
- Feeds frames into the Gemini Live WebSocket as inline image parts

### 2. Audio Pipeline
- Captures microphone audio at 16kHz mono PCM (from glasses mic or iPhone mic)
- Streams audio chunks to Gemini Live in real-time
- Receives audio responses from Gemini and plays through the glasses speaker (or iPhone speaker)
- Handles echo cancellation and noise suppression via AVAudioEngine

### 3. Mode Router
- Central state machine that determines the current operating mode
- Each mode defines its own system instruction, tool set, and UI overlay
- Modes can be switched via voice command ("switch to translator mode") or UI picker
- Only one mode active at a time; clean teardown/setup on switch

### 4. Gemini Live Service
- Manages the WebSocket connection to Gemini's multimodal live API
- Handles session creation, configuration updates, and reconnection
- Multiplexes vision frames + audio into the stream
- Parses responses: audio chunks, text transcripts, and tool calls
- Tool calls are routed to OpenClaw or handled locally

### 5. OpenClaw Bridge
- HTTP client connecting to the OpenClaw Gateway on the local network
- Discovers gateway via mDNS/Bonjour (`.local` hostname)
- Translates Gemini tool calls into OpenClaw skill invocations
- Returns results back to Gemini for conversational integration

## Key Use Cases

### Mode 1: Assistant (Default)
- General-purpose AI assistant with eyes and ears
- "What am I looking at?" â€” scene description
- "Read that sign" â€” OCR and interpretation
- "Remember this" â€” save visual context to memory
- System instruction: helpful assistant with vision and tool access

### Mode 2: Translator
- Real-time Mandarin â†” English translation
- Hears speech in one language, responds in the other
- Visual translation: point at text, get translation overlaid
- System instruction: you are a translator, always translate between Mandarin and English
- Future: support additional language pairs

### Mode 3: QR Scanner
- Continuous QR code detection from camera frames
- On detection: parse URL/data, present action options
- Actions: open link, add contact, connect WiFi, trigger OpenClaw skill
- Uses Vision framework's VNDetectBarcodesRequest
- System instruction: minimal â€” QR mode is mostly local processing

### Mode 4: Spotter
- "Spot check" mode for specific visual tasks
- Configure what to watch for: specific objects, people, text, events
- Alert when spotted: "I see a parking spot on your left"
- Runs continuous frame analysis with a focused prompt
- System instruction: watch for [configured items], alert immediately when seen

### Mode 5: Navigator
- Contextual navigation assistance
- "Where's the nearest coffee shop?" â†’ OpenClaw web search + directions
- "What bus is that?" â†’ read bus number from camera, look up route
- Combines vision (reading signs, numbers) with OpenClaw (search, maps)
- Future: AR overlay directions

### Mode 6: Custom
- User-defined modes via custom system instructions
- Configure via Settings: name, system instruction, tools enabled
- Share mode configs as JSON
- Power user feature for specific workflows

## Technical Decisions

| Decision | Choice | Rationale |
|----------|--------|-----------|
| Language | Swift | Native iOS, best performance for real-time AV |
| Min iOS | 17.0 | Required for modern SwiftUI, Vision APIs |
| Architecture | MVVM | Clean separation, SwiftUI-friendly |
| Gemini API | Multimodal Live API | Real-time streaming, vision + audio + tools |
| Audio format | 16kHz mono PCM | Gemini's preferred input format |
| Frame format | JPEG, 80% quality | Good balance of size vs quality for vision |
| Frame rate | 1 fps to Gemini | Cost/latency balance; configurable |
| Networking | URLSession WebSocket | Native, no dependencies for WS |
| OpenClaw | HTTP REST | Simple, reliable, LAN-only |
| QR Detection | Vision framework | Native, fast, no dependencies |
| Config | UserDefaults + JSON | Simple persistence, exportable configs |

## Project Structure

```
OpenGlass/
â”œâ”€â”€ App/
â”‚   â”œâ”€â”€ OpenGlassApp.swift          # App entry point
â”‚   â””â”€â”€ ContentView.swift           # Root view with mode routing
â”œâ”€â”€ Config/
â”‚   â””â”€â”€ OpenGlassConfig.swift       # Configuration management
â”œâ”€â”€ Gemini/
â”‚   â”œâ”€â”€ GeminiLiveService.swift     # WebSocket connection manager
â”‚   â”œâ”€â”€ GeminiSessionViewModel.swift # Session state & UI binding
â”‚   â””â”€â”€ AudioManager.swift          # Audio capture & playback
â”œâ”€â”€ Vision/
â”‚   â”œâ”€â”€ GlassesCameraManager.swift  # Meta Ray-Ban DAT SDK integration
â”‚   â”œâ”€â”€ IPhoneCameraManager.swift   # Fallback iPhone camera
â”‚   â”œâ”€â”€ FrameThrottler.swift        # Frame rate limiting
â”‚   â””â”€â”€ QRDetector.swift            # QR/barcode detection
â”œâ”€â”€ Modes/
â”‚   â”œâ”€â”€ ModeProtocol.swift          # Mode interface definition
â”‚   â”œâ”€â”€ ModeRouter.swift            # Mode state machine
â”‚   â”œâ”€â”€ AssistantMode.swift         # General assistant mode
â”‚   â”œâ”€â”€ TranslatorMode.swift        # Translation mode
â”‚   â”œâ”€â”€ QRScannerMode.swift         # QR scanning mode
â”‚   â””â”€â”€ SpotterMode.swift           # Visual spotter mode
â”œâ”€â”€ OpenClaw/
â”‚   â”œâ”€â”€ OpenClawBridge.swift        # Gateway HTTP client
â”‚   â”œâ”€â”€ ToolCallRouter.swift        # Tool call dispatch
â”‚   â””â”€â”€ ToolCallModels.swift        # Tool call data models
â”œâ”€â”€ UI/
â”‚   â”œâ”€â”€ GlassesConnectionView.swift # Glasses pairing UI
â”‚   â”œâ”€â”€ ModePickerView.swift        # Mode selection UI
â”‚   â”œâ”€â”€ TranscriptView.swift        # Live transcript display
â”‚   â””â”€â”€ SettingsView.swift          # App settings
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ MODES.md                    # Mode system documentation
â”‚   â””â”€â”€ SETUP.md                    # Setup guide
â”œâ”€â”€ SPEC.md                         # This file
â”œâ”€â”€ README.md                       # Project overview
â”œâ”€â”€ LICENSE                         # MIT License
â””â”€â”€ CONTRIBUTING.md                 # Contribution guide
```

## Build Phases

### Phase 1: Foundation (Week 1-2)
- [ ] Xcode project setup with SwiftUI
- [ ] Basic app shell with tab navigation
- [ ] iPhone camera capture (fallback mode)
- [ ] Frame throttling and JPEG encoding
- [ ] Audio capture via AVAudioEngine

### Phase 2: Gemini Integration (Week 3-4)
- [ ] Gemini Live WebSocket connection
- [ ] Audio streaming (send mic, receive responses)
- [ ] Vision frame streaming
- [ ] Basic tool call handling
- [ ] Session management (connect, disconnect, reconnect)

### Phase 3: OpenClaw Bridge (Week 5)
- [ ] Gateway discovery via mDNS
- [ ] HTTP client for skill invocation
- [ ] Tool call routing (Gemini â†’ OpenClaw)
- [ ] Result integration back to Gemini

### Phase 4: Mode System (Week 6-7)
- [ ] Mode protocol and router
- [ ] Assistant mode (default)
- [ ] Translator mode
- [ ] QR Scanner mode
- [ ] Spotter mode
- [ ] Mode switching via voice and UI

### Phase 5: Polish & Glasses (Week 8-10)
- [ ] Meta Ray-Ban DAT SDK integration
- [ ] Glasses connection UI
- [ ] Audio routing (glasses speaker)
- [ ] Settings and configuration
- [ ] Error handling and reconnection
- [ ] Performance optimization

### Phase 6: Advanced Features (Ongoing)
- [ ] Navigator mode
- [ ] Custom mode builder
- [ ] Conversation history / memory
- [ ] Widget for quick mode switching
- [ ] Shortcuts integration

## Future Ideas

- **AR Overlay**: When Apple supports it, overlay translations/annotations in the glasses view
- **Multi-language Translation**: Extend beyond Mandarin â†” English
- **Offline Mode**: On-device models for basic functionality without internet
- **Wearable Integration**: Apple Watch companion for quick mode switching
- **Social Features**: Share what you're seeing with friends via OpenClaw messaging
- **Developer SDK**: Let others build OpenGlass modes as plugins
- **Recording**: Save interesting moments with AI-generated summaries
- **Accessibility**: Describe scenes for visually impaired users (ironic with glasses, but useful for camera-only mode)

## Hardware Requirements

- **iPhone**: iOS 17.0+, iPhone 12 or later recommended
- **Smart Glasses**: Meta Ray-Ban (2024+) with DAT SDK support
- **Network**: Wi-Fi for OpenClaw Gateway access; cellular for Gemini API
- **OpenClaw**: Mac running OpenClaw Gateway on the same LAN

## References

- [VisionClaw](https://github.com/sseanliu/VisionClaw) â€” Sean Liu's Gemini Live + OpenClaw glasses project
- [Gemini Multimodal Live API](https://ai.google.dev/gemini-api/docs/multimodal-live) â€” Google's real-time multimodal API
- [OpenClaw](https://openclaw.app) â€” AI agent gateway with 56+ skills
- [Meta DAT SDK](https://developers.meta.com/horizon/documentation/dat/dat-overview) â€” Direct Audio Transfer SDK for Ray-Ban Meta glasses
- [Vision Framework](https://developer.apple.com/documentation/vision) â€” Apple's computer vision framework
